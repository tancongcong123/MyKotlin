整体架构
    是一个结合了分布式理论和具体的工程开发的整体架构，就是要使用大量的普通计算机处理大规模数据的存储和分析
    ，而不是建造一个超级计算机，这需要解决两个问题：
        1 计算机故障的问题：要做到一台机器的故障不能影响整个计算机集群
        2 数据的依赖问题：集群由若干台计算机组成，数据也分布在不同的计算机上面，当计算一个任务的时候，所需的数据可能需要从不同的机器上进行读取
            ，而计算的过程也要分配到不同的计算机上，当任务分成若干个步骤形成相互依赖的关系时，如何让系统保持高校和正确是一个很大的问题
Hadoop有非常多的组件但其中最核心的两部分依然是[底层文件文件系统HDFS]和[用于计算的MapReduce]
    HDFS（分布式文件系统）
        帮助解决文件的底层存储问题，能够用来支持海量数据的磁盘存储，能够进行机器的线性扩展，只需要在集群中增加节点，存储能力就会同步增长
        此外还具有强大的容错性能，某些节点出现故障不会影响系统的使用，通常数据都有很多副本。
        HDFS屏蔽了很多存储细节，并在客户端提供了一套完整的文件管理命令，把底层文件以一种结构化的目录形式展现出来。
        可以使用类似Linux文件操作命令一样使用Hadoop命令来访问对应的文件
    MapReduce（分布式计算框架）
        解决分布式计算的问题，包括其中的运算逻辑和数据依赖。
        在MapReduce应用上，提供了一套编程模型，重点就是实现map函数和reduce函数
            map函数用于组织和分割数据
            reduce函数主要负责在分布式节点上的数据运算
        支持多种语言实现，如java、Scala等
    Hive（数仓系统）
        数据仓库工具，用于将结构化的数据文件映射成一个数据表，HDFS文件系统可以存储结构化的数据文件，也可以存储非结构化的数据文件，Hive是处理器中的结构化数据文件，本身不进行存储
        Hive提供一套Hive SQL实现MapReduce计算，可以使用和SQL十分类似的Hive SQL对这些结构化的数据进行统计分析
        不能进行单条数据更新
    HBase（分布式数据库）
        是一个分布式高并发的k-v数据库系统，底层由HDFS支撑，通过对存储内容的重新组织，克服了HDFS对小文件处理困难的问题，实现了数据操作。
        一般对量级较大且变动较多的数据通常适合使用HBase进行存取
    Yarn（资源调度和管理框架）
    ZooKeeper（分布式协作服务）
        服务的注册管理中心，生产者把所提供的服务提交到ZooKeeper，消费者则去ZooKeeper中寻找所需要的服务，从中获取信息，再去调用生产者的服务
        把控各种数据流转服务的中间环节，保障了数据的一致性
        比如HBase、kafka等都可以通过ZooKeeper进行注册
免费的Hadoop版本
    Apache版本，原始的发行版
    Cloudera版本，简称CDH
    Hortonworks版本，简称HDP
    所有版本都是基于Apache版本进行改进的
Hadoop总结
    优点
        强大的数据存储和处理能力
        隐藏了大量的技术细节
        良好的扩展能力
            例如很多都使用性能更好的Spark、Flink替换MapReduce
    缺点
        实时性较差
            HDFS和MapReduce都是在磁盘中进行的，所以实时性不好
        学习难度大